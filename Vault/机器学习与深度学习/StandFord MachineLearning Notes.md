
- Gradient Descent
> The job of gradient descent is to find the value of theta for you that hopefully minimizes the cost function J(theta).
> 意义在于寻找一个theta 用于将损失函数J()最小化


- 线性代数review 
用矩阵向量形式表示预测函数：算法需要+代码简洁易懂

- Classification


- Linear regression with multiple variables is also known as "multivariate linear regression".



- Gradient Descent in Practice
Two techniques to help with this are **feature scaling** and **mean normalization**. Feature scaling involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. Mean normalization involves subtracting the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero.

- Normal Equation
a method to solve thetha analytically.
only 1 step to the answer


## Logistic Regression
- Hypothesis Represention

- Decision Boundary